{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Get the data\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\"\n",
        "\n",
        "# Function to read and process the data\n",
        "def read_data(file_path):\n",
        "    df = pd.read_csv(file_path, sep='\\t', header=None, names=['label', 'message'])\n",
        "    # Convert labels to binary (0 for ham, 1 for spam)\n",
        "    df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "    return df\n",
        "\n",
        "# Read training and testing data\n",
        "try:\n",
        "    train_data = read_data(train_file_path)\n",
        "    test_data = read_data(test_file_path)\n",
        "    print(\"Data loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "    # If there's an issue loading the data, create sample data for demonstration\n",
        "    print(\"Creating sample data for demonstration...\")\n",
        "\n",
        "    # Sample ham messages\n",
        "    ham_messages = [\n",
        "        \"Hey what's up?\",\n",
        "        \"I'll be there in 10 minutes\",\n",
        "        \"Can you pick up some milk on your way home?\",\n",
        "        \"Don't forget we have dinner at 7\",\n",
        "        \"How was your day?\",\n",
        "        \"Call me when you get a chance\"\n",
        "    ]\n",
        "\n",
        "    # Sample spam messages\n",
        "    spam_messages = [\n",
        "        \"CONGRATULATIONS! You've won a $1000 gift card! Click here to claim now!\",\n",
        "        \"FREE entry to concert this weekend! Reply YES to confirm\",\n",
        "        \"Your account has been charged $350. If this was not you, call immediately\",\n",
        "        \"You have won a free vacation! Call now to claim your prize\",\n",
        "        \"50% OFF all items! Limited time offer!\",\n",
        "        \"Your payment is due. Reply with STOP to unsubscribe\"\n",
        "    ]\n",
        "\n",
        "    # Create training data\n",
        "    train_ham = pd.DataFrame({'label': [0] * 40, 'message': np.random.choice(ham_messages, 40)})\n",
        "    train_spam = pd.DataFrame({'label': [1] * 20, 'message': np.random.choice(spam_messages, 20)})\n",
        "    train_data = pd.concat([train_ham, train_spam]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    # Create testing data\n",
        "    test_ham = pd.DataFrame({'label': [0] * 10, 'message': np.random.choice(ham_messages, 10)})\n",
        "    test_spam = pd.DataFrame({'label': [1] * 5, 'message': np.random.choice(spam_messages, 5)})\n",
        "    test_data = pd.concat([test_ham, test_spam]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Display information about the data\n",
        "print(f\"Training data shape: {train_data.shape}\")\n",
        "print(f\"Testing data shape: {test_data.shape}\")\n",
        "print(\"\\nClass distribution in training data:\")\n",
        "print(train_data['label'].value_counts())\n",
        "print(\"\\nClass distribution in testing data:\")\n",
        "print(test_data['label'].value_counts())\n",
        "\n",
        "# Display some examples\n",
        "print(\"\\nSample ham messages:\")\n",
        "print(train_data[train_data['label'] == 0]['message'].head(3).values)\n",
        "print(\"\\nSample spam messages:\")\n",
        "print(train_data[train_data['label'] == 1]['message'].head(3).values)\n",
        "\n",
        "# Prepare the data for the model\n",
        "# Extract features and labels\n",
        "train_sentences = train_data['message'].values\n",
        "train_labels = train_data['label'].values\n",
        "test_sentences = test_data['message'].values\n",
        "test_labels = test_data['label'].values\n",
        "\n",
        "# Tokenize the text\n",
        "vocab_size = 10000\n",
        "max_length = 100\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = '<OOV>'\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "# Get the word index\n",
        "word_index = tokenizer.word_index\n",
        "print(f\"\\nVocabulary size: {len(word_index)}\")\n",
        "\n",
        "# Convert text to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "# Pad the sequences\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Build the model\n",
        "embedding_dim = 16\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 30\n",
        "history = model.fit(\n",
        "    train_padded, train_labels,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=(test_padded, test_labels),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_padded, test_labels)\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Create the prediction function\n",
        "def predict_message(message):\n",
        "    # Tokenize the message\n",
        "    sequence = tokenizer.texts_to_sequences([message])\n",
        "    # Pad the sequence\n",
        "    padded = pad_sequences(sequence, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "    # Make prediction\n",
        "    prediction = model.predict(padded)[0][0]\n",
        "\n",
        "    # Return probability and classification\n",
        "    return [float(prediction), \"spam\" if prediction > 0.5 else \"ham\"]\n",
        "\n",
        "# Test the prediction function with some examples\n",
        "test_messages = [\n",
        "    \"Hey, how's it going?\",\n",
        "    \"Congratulations! You've won a free cruise. Call now to claim your prize!\"\n",
        "]\n",
        "\n",
        "for message in test_messages:\n",
        "    prediction = predict_message(message)\n",
        "    print(f\"Message: {message}\")\n",
        "    print(f\"Prediction: {prediction[1]} (Probability: {prediction[0]:.4f})\")\n",
        "    print()\n",
        "\n",
        "# The code below is for the FreeCodeCamp test cell\n",
        "# You can test your model with:\n",
        "def test_predictions():\n",
        "    test_messages = [\n",
        "        \"how are you doing today\",\n",
        "        \"sale today! to stop texts call 98912460324\",\n",
        "        \"i dont want to go. can we try it a different day? available sat\",\n",
        "        \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "        \"you have won Â£1000 cash! call to claim your prize.\",\n",
        "        \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "        \"wow, is your arm alright. that happened to me one time too\"\n",
        "    ]\n",
        "\n",
        "    test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "    passed = True\n",
        "\n",
        "    for msg, ans in zip(test_messages, test_answers):\n",
        "        prediction = predict_message(msg)\n",
        "        if prediction[1] != ans:\n",
        "            passed = False\n",
        "\n",
        "    if passed:\n",
        "        print(\"All tests passed!\")\n",
        "    else:\n",
        "        print(\"Some tests failed.\")\n",
        "\n",
        "# Run the tests\n",
        "test_predictions()"
      ],
      "metadata": {
        "id": "85T_tBoLz-a-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "fcc_sms_text_classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}